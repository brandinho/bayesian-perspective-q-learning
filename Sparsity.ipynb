{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sparsity.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5sAJsTsjHiqBYwZiAicBF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brandinho/bayesian-perspective-q-learning/blob/main/Sparsity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11H-ZRHRRY-x"
      },
      "source": [
        "# The Effect of Sparsity\n",
        "\n",
        "We explore what happens to the effective number of timesteps, $\\widetilde{N}$, as sparsity increases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SseZeZ9BLviv"
      },
      "source": [
        "# Import Packages\n",
        "\n",
        "import numpy as np\n",
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cXEcD-mJIyL"
      },
      "source": [
        "Below we create the functions to calculate the effective number of timesteps. We consider evenly spaced sparsity, as well as randomly placed sparsity (via all of the permutations). We define the theoretical number of effective timesteps that is outlined in our paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRW_w0tAO8Ig",
        "cellView": "both"
      },
      "source": [
        "# Functions to calculate the effective number of timesteps\n",
        "\n",
        "def get_effective_timesteps_empirical_evenly_spaced(N, gamma, sparsity):\n",
        "    effective_timesteps = []\n",
        "    discount_factors = gamma**np.arange(N)\n",
        "    for starting_point in range(sparsity):\n",
        "        current_discount = np.zeros_like(discount_factors)\n",
        "        current_discount[starting_point::sparsity] = discount_factors[starting_point::sparsity]\n",
        "        effective_timesteps.append(np.sum(current_discount))\n",
        "    return np.mean(effective_timesteps), effective_timesteps\n",
        "\n",
        "def get_effective_timesteps_empirical_permutations(N, gamma, sparsity):\n",
        "    effective_timesteps = []\n",
        "    discount_factors = gamma**np.arange(N)\n",
        "    for i in itertools.combinations(enumerate(discount_factors), int(N/sparsity)):\n",
        "        effective_timesteps.append(sum([y for x, y in i]))\n",
        "    return np.mean(effective_timesteps)\n",
        "\n",
        "def get_effective_timesteps_theoretical(N, gamma, sparsity):\n",
        "    discount_factors = gamma**np.arange(N)\n",
        "    return np.sum(discount_factors) * (1 / sparsity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPv5IvXLJeRa"
      },
      "source": [
        "We show that our theoretical formulation for effective number of timesteps (as outlined in the paper) is equal to the empirical average across all permutations (i.e. all of the different places that sparsity can occur)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihEK3liHXnWS",
        "outputId": "efe7b73f-f741-41b5-c4b3-a969f3dd55b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@title Play Around with the Parameters { form-width: \"400px\" }\n",
        "\n",
        "N = 20 #@param {type:\"slider\", min:5, max:20, step:1}\n",
        "gamma = 0.95 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "max_sparsity = 20 #@param {type:\"slider\", min:5, max:20, step:1}\n",
        "\n",
        "print(\"Evenly Spaced Rewards\")\n",
        "for sparsity in range(1, max_sparsity + 1):\n",
        "    empicical_timesteps, all_empirical_timesteps = get_effective_timesteps_empirical_evenly_spaced(N, gamma, sparsity)\n",
        "    theoretical_timesteps = get_effective_timesteps_theoretical(N, gamma, sparsity)\n",
        "    \n",
        "    print(\"\\nSparsity: {}\".format(sparsity))\n",
        "    print(\"Empirical Average: {}\".format(empicical_timesteps))\n",
        "    print(\"Theoretical: {}\".format(theoretical_timesteps))\n",
        "\n",
        "print(\"Rest of the Permutations\")\n",
        "for sparsity in range(1, max_sparsity + 1):\n",
        "    # Only use the sparsity values that are multiples of N (to get the exact number of combinations in itertools)\n",
        "    if N % sparsity == 0:\n",
        "        empicical_timesteps = get_effective_timesteps_empirical_permutations(N, gamma, sparsity)\n",
        "        theoretical_timesteps = get_effective_timesteps_theoretical(N, gamma, sparsity)\n",
        "        \n",
        "        print(\"\\nSparsity: {}\".format(sparsity))\n",
        "        print(\"Empirical Average: {}\".format(empicical_timesteps))\n",
        "        print(\"Theoretical: {}\".format(theoretical_timesteps))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evenly Spaced Rewards\n",
            "\n",
            "Sparsity: 1\n",
            "Empirical Average: 12.830281551829152\n",
            "Theoretical: 12.830281551829152\n",
            "\n",
            "Sparsity: 2\n",
            "Empirical Average: 6.415140775914575\n",
            "Theoretical: 6.415140775914576\n",
            "\n",
            "Sparsity: 3\n",
            "Empirical Average: 4.276760517276384\n",
            "Theoretical: 4.276760517276384\n",
            "\n",
            "Sparsity: 4\n",
            "Empirical Average: 3.207570387957287\n",
            "Theoretical: 3.207570387957288\n",
            "\n",
            "Sparsity: 5\n",
            "Empirical Average: 2.56605631036583\n",
            "Theoretical: 2.5660563103658305\n",
            "\n",
            "Sparsity: 6\n",
            "Empirical Average: 2.138380258638192\n",
            "Theoretical: 2.138380258638192\n",
            "\n",
            "Sparsity: 7\n",
            "Empirical Average: 1.8328973645470215\n",
            "Theoretical: 1.8328973645470217\n",
            "\n",
            "Sparsity: 8\n",
            "Empirical Average: 1.6037851939786438\n",
            "Theoretical: 1.603785193978644\n",
            "\n",
            "Sparsity: 9\n",
            "Empirical Average: 1.4255868390921278\n",
            "Theoretical: 1.425586839092128\n",
            "\n",
            "Sparsity: 10\n",
            "Empirical Average: 1.2830281551829152\n",
            "Theoretical: 1.2830281551829152\n",
            "\n",
            "Sparsity: 11\n",
            "Empirical Average: 1.1663892319844682\n",
            "Theoretical: 1.1663892319844684\n",
            "\n",
            "Sparsity: 12\n",
            "Empirical Average: 1.069190129319096\n",
            "Theoretical: 1.069190129319096\n",
            "\n",
            "Sparsity: 13\n",
            "Empirical Average: 0.9869447347560883\n",
            "Theoretical: 0.9869447347560887\n",
            "\n",
            "Sparsity: 14\n",
            "Empirical Average: 0.9164486822735106\n",
            "Theoretical: 0.9164486822735108\n",
            "\n",
            "Sparsity: 15\n",
            "Empirical Average: 0.8553521034552767\n",
            "Theoretical: 0.8553521034552768\n",
            "\n",
            "Sparsity: 16\n",
            "Empirical Average: 0.8018925969893218\n",
            "Theoretical: 0.801892596989322\n",
            "\n",
            "Sparsity: 17\n",
            "Empirical Average: 0.7547224442252441\n",
            "Theoretical: 0.7547224442252443\n",
            "\n",
            "Sparsity: 18\n",
            "Empirical Average: 0.712793419546064\n",
            "Theoretical: 0.712793419546064\n",
            "\n",
            "Sparsity: 19\n",
            "Empirical Average: 0.6752779764120607\n",
            "Theoretical: 0.6752779764120607\n",
            "\n",
            "Sparsity: 20\n",
            "Empirical Average: 0.6415140775914576\n",
            "Theoretical: 0.6415140775914576\n",
            "Rest of the Permutations\n",
            "\n",
            "Sparsity: 1\n",
            "Empirical Average: 12.830281551829152\n",
            "Theoretical: 12.830281551829152\n",
            "\n",
            "Sparsity: 2\n",
            "Empirical Average: 6.4151407759145735\n",
            "Theoretical: 6.415140775914576\n",
            "\n",
            "Sparsity: 4\n",
            "Empirical Average: 3.2075703879572877\n",
            "Theoretical: 3.207570387957288\n",
            "\n",
            "Sparsity: 5\n",
            "Empirical Average: 2.5660563103658305\n",
            "Theoretical: 2.5660563103658305\n",
            "\n",
            "Sparsity: 10\n",
            "Empirical Average: 1.283028155182915\n",
            "Theoretical: 1.2830281551829152\n",
            "\n",
            "Sparsity: 20\n",
            "Empirical Average: 0.6415140775914576\n",
            "Theoretical: 0.6415140775914576\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}